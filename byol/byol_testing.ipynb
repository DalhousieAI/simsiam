{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfyanzOftE40"
   },
   "outputs": [],
   "source": [
    "def set_requires_grad(model, val):\n",
    "    \"\"\"\n",
    "    Set pytorch model's require grad property to val.\n",
    "\n",
    "    Copyright (c) 2020 Phil Wang Redistributed under the MIT license.\n",
    "    Function taken from: https://github.com/lucidrains/byol-pytorch\n",
    "    \"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = val\n",
    "\n",
    "\n",
    "def ema(target_param, online_param, alpha):\n",
    "    if alpha is None:\n",
    "        return online_param\n",
    "    return alpha * target_param + (1 - alpha) * online_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yAC2ueYzT7mK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BYOL(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a BYOL model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_encoder : torch.nn.Module\n",
    "        Base encoder model.\n",
    "    dim : int, default=2048\n",
    "        Feature dimension\n",
    "    pred_dim : int, default=512\n",
    "        Hidden dimension of the predictor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_encoder, init_target_from_online, dim=2048, pred_dim=512):\n",
    "        super(BYOL, self).__init__()\n",
    "\n",
    "        # create the online encoder\n",
    "        # num_classes is the output fc dimension, zero-initialize last BNs\n",
    "        self.encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
    "\n",
    "        # build a 3-layer online projector\n",
    "        prev_dim = self.encoder.fc.weight.shape[1]\n",
    "        self.encoder.fc = nn.Sequential(\n",
    "            nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "            nn.BatchNorm1d(prev_dim),\n",
    "            nn.ReLU(inplace=True),  # first layer\n",
    "            nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "            nn.BatchNorm1d(prev_dim),\n",
    "            nn.ReLU(inplace=True),  # second layer\n",
    "            self.encoder.fc,\n",
    "            nn.BatchNorm1d(dim, affine=False),\n",
    "        )  # output layer\n",
    "        self.encoder.fc[\n",
    "            6\n",
    "        ].bias.requires_grad = False  # hack: not use bias as it is followed by BN\n",
    "\n",
    "        # build target model\n",
    "        self.target_encoder = base_encoder(num_classes=dim, zero_init_residual=True)\n",
    "        self.target_encoder.fc = nn.Sequential(\n",
    "            nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "            nn.BatchNorm1d(prev_dim),\n",
    "            nn.ReLU(inplace=True),  # first layer\n",
    "            nn.Linear(prev_dim, prev_dim, bias=False),\n",
    "            nn.BatchNorm1d(prev_dim),\n",
    "            nn.ReLU(inplace=True),  # second layer\n",
    "            self.target_encoder.fc,\n",
    "            nn.BatchNorm1d(dim, affine=False),\n",
    "        )  # output layer\n",
    "\n",
    "        if init_target_from_online:\n",
    "            self.target_encoder.load_state_dict(self.encoder.state_dict())\n",
    "\n",
    "        # disable grad calculations for target model\n",
    "        set_requires_grad(self.target_encoder, False)\n",
    "\n",
    "        # build a 2-layer predictor\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(dim, pred_dim, bias=False),\n",
    "            nn.BatchNorm1d(pred_dim),\n",
    "            nn.ReLU(inplace=True),  # hidden layer\n",
    "            nn.Linear(pred_dim, dim),\n",
    "        )  # output layer\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Forward step.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : torch.Tensor\n",
    "            First view of images.\n",
    "        x2 : torch.Tensor\n",
    "            Second view of images.\n",
    "        Return\n",
    "        ------\n",
    "        p1, p2, z1, z2 :\n",
    "            online predictors and target projections of the networks\n",
    "        Note\n",
    "        ----\n",
    "        See https://arxiv.org/abs/2006.07733 for detailed notations\n",
    "        \"\"\"\n",
    "        # compute features for one view\n",
    "        z1 = self.encoder(x1)  # NxC\n",
    "        z2 = self.encoder(x2)  # NxC\n",
    "        z1_target = self.target_encoder(x1)\n",
    "        z2_target = self.target_encoder(x2)\n",
    "\n",
    "        p1 = self.predictor(z1)  # NxC\n",
    "        p2 = self.predictor(z2)  # NxC\n",
    "\n",
    "        return p1, p2, z1_target, z2_target\n",
    "\n",
    "    def update_target(self, target_model, online_model, alpha=0.99):\n",
    "        target_state_dict = target_model.state_dict()\n",
    "        for param in target_state_dict:\n",
    "            target_state_dict[param] = ema(\n",
    "                target_state_dict[param], online_model.state_dict()[param], alpha\n",
    "            )\n",
    "        target_model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoyzMB79VAyP"
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "import torchvision.models as models\n",
    "\n",
    "arch = \"resnet18\"\n",
    "init_target_from_online = False\n",
    "\n",
    "encoder = models.__dict__[arch]\n",
    "model = BYOL(encoder, init_target_from_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfwKRnaywb1v",
    "outputId": "df5db4d9-38ec-4282-950a-0ebae8d4b53a"
   },
   "outputs": [],
   "source": [
    "# online and target aren't the same reference - should return false\n",
    "print(model.encoder.fc == model.target_encoder.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvVohkRYqcVM",
    "outputId": "4efc0071-6baa-4c5f-eed3-b62ca58c1ec5"
   },
   "outputs": [],
   "source": [
    "# autograd check for online - should be all true except for fc 6's biases\n",
    "for name, param in model.encoder.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "\n",
    "for name, param in model.predictor.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWA0kdSIqYzR",
    "outputId": "561139df-426a-4265-c76e-a2ece568e28e"
   },
   "outputs": [],
   "source": [
    "# autograd check for target - should be all false\n",
    "for name, param in model.target_encoder.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbFejsiOFqBX",
    "outputId": "6ea69aa3-f172-4c4f-d415-8ac39d601f96"
   },
   "outputs": [],
   "source": [
    "# check to see if weights between online and target are identical\n",
    "target_online_init = True\n",
    "for param in zip(model.target_encoder.parameters(), model.encoder.parameters()):\n",
    "    if not (param[0] == param[1]).all():\n",
    "        target_online_init = False\n",
    "print(target_online_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrhHj8gsZCwk",
    "outputId": "f173c700-6466-492b-f7fc-02ad4ee15655"
   },
   "outputs": [],
   "source": [
    "# check to see if target model is properly randomly initialized\n",
    "# true - if properly randomly initialized\n",
    "# false - if initialized from online or improperly randomly initialized\n",
    "# list constructed from remaking target_encoder from scratch\n",
    "reset_target_check = [\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "    True,\n",
    "    False,\n",
    "    False,\n",
    "]\n",
    "\n",
    "reset_test_results = []\n",
    "\n",
    "for param in zip(model.target_encoder.parameters(), model.encoder.parameters()):\n",
    "    reset_test_results.append(bool((param[0] == param[1]).all()))\n",
    "\n",
    "proper_random_init = reset_test_results == reset_target_check\n",
    "print(proper_random_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tox_vtJJCkfB",
    "outputId": "66311e34-5ae4-43f6-974e-9c808348bea9"
   },
   "outputs": [],
   "source": [
    "# check if ema works properly - should return true\n",
    "import random\n",
    "\n",
    "a = random.randint(-10, 10) * random.random()\n",
    "b = random.randint(-10, 10) * random.random()\n",
    "alpha = random.random()\n",
    "print(ema(a, b, alpha) == alpha * a + (1 - alpha) * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6KdIBPtFlz_",
    "outputId": "9cb55c73-32b7-4a71-bdcf-e2165a3e14d8"
   },
   "outputs": [],
   "source": [
    "# check if update target model works properly\n",
    "# should return true\n",
    "import copy\n",
    "\n",
    "alpha = random.random()\n",
    "target_original = copy.deepcopy(model.target_encoder)\n",
    "proper_target_update = True\n",
    "\n",
    "if not proper_random_init:\n",
    "    print(\"Target model may not have been properly randomly intialized.\")\n",
    "\n",
    "model.update_target(model.target_encoder, model.encoder, alpha)\n",
    "\n",
    "for param in zip(\n",
    "    model.target_encoder.parameters(),\n",
    "    target_original.parameters(),\n",
    "    model.encoder.parameters(),\n",
    "):\n",
    "    if not (param[0] == ema(param[1], param[2], alpha)).all():\n",
    "        proper_target_update = False\n",
    "\n",
    "print(proper_target_update)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "byol_testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
